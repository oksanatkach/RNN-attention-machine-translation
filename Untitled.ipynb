{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_builtins = True\n",
    "punctuation = '.?!,'\n",
    "acceptable_chars = punctuation + ' abcdefghijklmnopqrstuvwxyzабвгґдеєжзиіїйклмнопрстуфхцчшщьюя'\n",
    "acceptable_chars = tensorflow_text.normalize_utf8(acceptable_chars, 'NFKD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = open(path, 'r', encoding='utf-8').read()\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp.lower() for targ, inp, _ in pairs]\n",
    "    targ = [targ.lower() for targ, inp, _ in pairs]\n",
    "\n",
    "  return inp, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # Split accecented characters.\n",
    "    text = tensorflow_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^' + acceptable_chars + ']', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[' + punctuation + ']', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw data\n",
    "path_to_data = 'ukr-eng/ukr.txt'\n",
    "inp, targ = load_data(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset\n",
    "BUFFER_SIZE = len(inp) # whole dataset size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vectorization\n",
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "input_text_processor.adapt(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  2   1  36 ...   0   0   0]\n",
      " [  2   6 137 ...   0   0   0]\n",
      " [  2   7   8 ...   0   0   0]\n",
      " ...\n",
      " [  2  24  63 ...   0   0   0]\n",
      " [  2   6 800 ...   0   0   0]\n",
      " [  2  10  43 ...   0   0   0]], shape=(64, 20), dtype=int64)\n",
      "5000\n",
      "[START] [UNK] за [UNK] тома . [END]             \n"
     ]
    }
   ],
   "source": [
    "# print prepped sentence\n",
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    example_tokens = input_text_processor(example_input_batch)\n",
    "    print(example_tokens)\n",
    "    input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "    print(len(input_vocab))\n",
    "    tokens = input_vocab[example_tokens[0].numpy()]\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "input_vocab_size = input_text_processor.vocabulary_size()\n",
    "embedding_layer = tf.keras.layers.Embedding(input_vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embedding_layer(example_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does GRU do?\n",
    "gru = tf.keras.layers.GRU(units,\n",
    "                          # Return the sequence and state\n",
    "                          return_sequences=True,\n",
    "                          return_state=True,\n",
    "                          recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, state = gru(vectors, initial_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 20, 1024), dtype=float32, numpy=\n",
       "array([[[-0.00240274, -0.00157611, -0.00623834, ...,  0.00461239,\n",
       "         -0.00182369, -0.00567733],\n",
       "        [ 0.00060355, -0.00030449, -0.00941917, ...,  0.00234954,\n",
       "         -0.00698494,  0.00062927],\n",
       "        [ 0.01221675, -0.00981983, -0.01610171, ...,  0.00381916,\n",
       "         -0.00231389, -0.00057539],\n",
       "        ...,\n",
       "        [-0.02529003,  0.00509631,  0.00576039, ...,  0.02044816,\n",
       "         -0.0259783 ,  0.00776972],\n",
       "        [-0.02525885,  0.00508721,  0.00577477, ...,  0.02048077,\n",
       "         -0.02598366,  0.00773164],\n",
       "        [-0.02523578,  0.0050831 ,  0.00578738, ...,  0.0205014 ,\n",
       "         -0.02598871,  0.0077064 ]],\n",
       "\n",
       "       [[-0.00240274, -0.00157611, -0.00623834, ...,  0.00461239,\n",
       "         -0.00182369, -0.00567733],\n",
       "        [ 0.00207801,  0.00336301, -0.00178579, ...,  0.00623163,\n",
       "         -0.0074925 , -0.00235636],\n",
       "        [ 0.00728533, -0.00611938,  0.00788238, ...,  0.00084702,\n",
       "         -0.01025532,  0.00286658],\n",
       "        ...,\n",
       "        [-0.02529781,  0.00510426,  0.00573452, ...,  0.02043083,\n",
       "         -0.02597041,  0.00779038],\n",
       "        [-0.02526366,  0.00509207,  0.00575763, ...,  0.02047281,\n",
       "         -0.02598029,  0.00774185],\n",
       "        [-0.02523874,  0.00508575,  0.00577612, ...,  0.02049832,\n",
       "         -0.02598778,  0.00771079]],\n",
       "\n",
       "       [[-0.00240274, -0.00157611, -0.00623834, ...,  0.00461239,\n",
       "         -0.00182369, -0.00567733],\n",
       "        [ 0.00701796,  0.00079728,  0.01278316, ..., -0.00049042,\n",
       "          0.00541001, -0.00718015],\n",
       "        [ 0.00874373,  0.0064518 ,  0.00682328, ...,  0.00682906,\n",
       "         -0.00387213, -0.01064768],\n",
       "        ...,\n",
       "        [-0.02525847,  0.00508619,  0.00577644, ...,  0.02052793,\n",
       "         -0.02599671,  0.0077468 ],\n",
       "        [-0.02523905,  0.00508248,  0.0057895 , ...,  0.02053293,\n",
       "         -0.02599666,  0.00771667],\n",
       "        [-0.02522334,  0.0050813 ,  0.00579947, ...,  0.02053536,\n",
       "         -0.02599835,  0.00769711]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.00240274, -0.00157611, -0.00623834, ...,  0.00461239,\n",
       "         -0.00182369, -0.00567733],\n",
       "        [-0.01497874,  0.00795952, -0.00191806, ...,  0.00783402,\n",
       "          0.00740718, -0.01768452],\n",
       "        [-0.00820102, -0.00013964, -0.00554629, ..., -0.00600998,\n",
       "         -0.00540168,  0.0007637 ],\n",
       "        ...,\n",
       "        [-0.02523096,  0.00507034,  0.00579875, ...,  0.02048239,\n",
       "         -0.02600894,  0.00771098],\n",
       "        [-0.0252198 ,  0.0050731 ,  0.00580506, ...,  0.02050138,\n",
       "         -0.02600693,  0.00769246],\n",
       "        [-0.02520985,  0.00507594,  0.00581002, ...,  0.02051375,\n",
       "         -0.02600667,  0.00768069]],\n",
       "\n",
       "       [[-0.00240274, -0.00157611, -0.00623834, ...,  0.00461239,\n",
       "         -0.00182369, -0.00567733],\n",
       "        [ 0.00207801,  0.00336301, -0.00178579, ...,  0.00623163,\n",
       "         -0.0074925 , -0.00235636],\n",
       "        [-0.00698375,  0.01259029, -0.00976457, ...,  0.00187675,\n",
       "         -0.00537442, -0.00218757],\n",
       "        ...,\n",
       "        [-0.02524856,  0.00509024,  0.00576823, ...,  0.02050473,\n",
       "         -0.02598579,  0.00773756],\n",
       "        [-0.02523034,  0.0050855 ,  0.00578228, ...,  0.02051667,\n",
       "         -0.02599066,  0.00771005],\n",
       "        [-0.02521611,  0.00508338,  0.00579359, ...,  0.02052398,\n",
       "         -0.02599532,  0.00769245]],\n",
       "\n",
       "       [[-0.00240274, -0.00157611, -0.00623834, ...,  0.00461239,\n",
       "         -0.00182369, -0.00567733],\n",
       "        [ 0.0051594 , -0.00266468, -0.01065302, ...,  0.00642316,\n",
       "         -0.00734078,  0.0007071 ],\n",
       "        [ 0.01724496,  0.00370368, -0.0010103 , ..., -0.0003198 ,\n",
       "         -0.00736884, -0.00980808],\n",
       "        ...,\n",
       "        [-0.02525633,  0.00509164,  0.0057627 , ...,  0.02047963,\n",
       "         -0.02602706,  0.00772229],\n",
       "        [-0.02523429,  0.0050864 ,  0.00577995, ...,  0.02050243,\n",
       "         -0.0260164 ,  0.00769781],\n",
       "        [-0.02521809,  0.00508429,  0.00579276, ...,  0.02051619,\n",
       "         -0.02601096,  0.00768306]]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT_experiments",
   "language": "python",
   "name": "mt_experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
